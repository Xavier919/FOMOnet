{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bdd79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from modules.visualize import *\n",
    "from modules.evaluate import *\n",
    "from modules.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb63cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pickle.load(open('data/dataset.pkl', 'rb'))\n",
    "trx_orfs = pickle.load(open('data/trx_orfs.pkl', 'rb'))\n",
    "ensembl_trx = pickle.load(open('data/ensembl_trx.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddd8f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fb635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tis_result = {}\n",
    "# Loop through the CSV files\n",
    "for i in range(6):\n",
    "    # Read the CSV file into a dataframe\n",
    "    df = pd.read_csv(f'preds/results{i}.csv')\n",
    "    # Convert the dataframe to a list of dictionaries\n",
    "    result = df.to_dict('records')\n",
    "    \n",
    "    # Loop through the list of dictionaries\n",
    "    for attrs in result:\n",
    "        trx = attrs['ID'].split(\" \")[0].split(\"'\")[1]\n",
    "        start = attrs['TIS_pos']\n",
    "        stop = attrs['TTS_pos']\n",
    "        out = attrs['output']\n",
    "        # Check if the trx already exists in the dictionary\n",
    "        if trx not in tis_result:\n",
    "            tis_result[trx] = {'start': start, \n",
    "                               'stop': stop, \n",
    "                               'out': out}\n",
    "        elif trx in tis_result and out > tis_result[trx]['out']:\n",
    "            tis_result[trx] = {'start': start, \n",
    "                               'stop': stop, \n",
    "                               'out': out}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b4f6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6f2951",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141a47f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = np.load('preds/results0.npy', allow_pickle=True)\n",
    "for i in range(data_array.shape[0]):\n",
    "    trx = data_array[i][2][0].split(' ')[0]\n",
    "    out = data_array[i][0][0]\n",
    "    data_dict[trx] = out\n",
    "data_array = np.load('preds/results1.npy', allow_pickle=True)\n",
    "for i in range(data_array.shape[0]):\n",
    "    trx = data_array[i][2][0].split(' ')[0]\n",
    "    out = data_array[i][0][0]\n",
    "    data_dict[trx] = out\n",
    "data_array = np.load('preds/results2.npy', allow_pickle=True)\n",
    "for i in range(data_array.shape[0]):\n",
    "    trx = data_array[i][2][0].split(' ')[0]\n",
    "    out = data_array[i][0][0]\n",
    "    data_dict[trx] = out\n",
    "data_array = np.load('preds/results3.npy', allow_pickle=True)\n",
    "for i in range(data_array.shape[0]):\n",
    "    trx = data_array[i][2][0].split(' ')[0]\n",
    "    out = data_array[i][0][0]\n",
    "    data_dict[trx] = out\n",
    "data_array = np.load('preds/results4.npy', allow_pickle=True)\n",
    "for i in range(data_array.shape[0]):\n",
    "    trx = data_array[i][2][0].split(' ')[0]\n",
    "    out = data_array[i][0][0]\n",
    "    data_dict[trx] = out\n",
    "data_array = np.load('preds/results5.npy', allow_pickle=True)\n",
    "for i in range(data_array.shape[0]):\n",
    "    trx = data_array[i][2][0].split(' ')[0]\n",
    "    out = data_array[i][0][0]\n",
    "    data_dict[trx] = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea131df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061d2da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tis_imputed = dict()\n",
    "for trx, output in data_dict.items():\n",
    "    if trx not in tis_result:\n",
    "        tis_imputed[trx] = output\n",
    "    else:\n",
    "        start = tis_result[trx]['start']\n",
    "        stop = tis_result[trx]['stop']\n",
    "        out = tis_result[trx]['out']\n",
    "        output[start:stop] = out\n",
    "        tis_imputed[trx] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08577bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tis_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f59437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f762f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = pickle.load(open('preds/reports.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e7f451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tis_reports = dict()\n",
    "for trx, attrs in reports.items():\n",
    "    out = None\n",
    "    if trx in tis_imputed:\n",
    "        out = torch.tensor(tis_imputed[trx])\n",
    "    else:\n",
    "        out = torch.ones(len(ensembl_trx[trx]['sequence']))\n",
    "    mapped_seq = attrs['mapped_seq']\n",
    "    mapped_cds = attrs['mapped_cds']\n",
    "    preds = bin_pred(out, 0.5)\n",
    "    recall = recall_score(mapped_cds, preds)\n",
    "    iou = iou_score(mapped_cds, preds)\n",
    "    tis_reports[trx] = {'out':out,\n",
    "                       'mapped_seq':mapped_seq,\n",
    "                       'mapped_cds':mapped_cds,\n",
    "                       'iou':iou,\n",
    "                       'recall':recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1387e5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7694a017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0288c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tis_reports, open('preds/tis_reports.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b767b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa01c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e624f57d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
